{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Try out np.genfromtxt to create np.array from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.BytesIO object at 0x104edb290>\n",
      "1, 2, 3\n",
      "4, 5, 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3.],\n",
       "       [ 4.,  5.,  6.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \"1, 2, 3\\n4, 5, 6\"\n",
    "print BytesIO(data)\n",
    "print data\n",
    "np.genfromtxt(BytesIO(data), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.502345269453031,31.70700584656992\r",
      "\r\n",
      "53.426804033275019,68.77759598163891\r",
      "\r\n",
      "61.530358025636438,62.562382297945803\r",
      "\r\n",
      "47.475639634786098,71.546632233567777\r",
      "\r\n",
      "59.813207869512318,87.230925133687393\r",
      "\r\n",
      "55.142188413943821,78.211518270799232\r",
      "\r\n",
      "52.211796692214001,79.64197304980874\r",
      "\r\n",
      "39.299566694317065,59.171489321869508\r",
      "\r\n",
      "48.10504169176825,75.331242297063056\r",
      "\r\n",
      "52.550014442733818,71.300879886850353\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 32.50234527,  31.70700585],\n",
       "       [ 53.42680403,  68.77759598]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = genfromtxt(\"data.csv\", delimiter=\",\")\n",
    "points[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### gradient descent find the best m and b quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/mattnedrich/GradientDescentExample/master/gradient_descent_example.gif\" width=\"500\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from IPython.display import Image\n",
    "Image(url='https://raw.githubusercontent.com/mattnedrich/GradientDescentExample/master/gradient_descent_example.gif', \n",
    "     width = 500, height=200)  \n",
    "# <img src=\"https://raw.githubusercontent.com/mattnedrich/GradientDescentExample/master/gradient_descent_example.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Sum of squared distances formula (to calculate our error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://spin.atomicobject.com/wp-content/uploads/linear_regression_error1.png\" width=\"500\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url = 'https://spin.atomicobject.com/wp-content/uploads/linear_regression_error1.png',\n",
    "     width = 500, height = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Gradient descent error surface\n",
    "\n",
    "- error evaluate how well a model fit all the dataset \n",
    "- the smaller the error, the best fit the model is\n",
    "- so, we need a search method(gradient descent here) to find smaller and smaller error and its corresponding (m, b)\n",
    "    - a unique pair of (m, b) correspond to a unique error value\n",
    "    - so, smallest error must correspond to one or a number of (m, b) pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://spin.atomicobject.com/wp-content/uploads/gradient_descent_error_surface.png\" width=\"500\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(height = 300, width = 500, url = 'https://spin.atomicobject.com/wp-content/uploads/gradient_descent_error_surface.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Partial derivative indicates whether we are going in the right direction or not\n",
    "- as gradient descent, we want to going downward\n",
    "- partial derivative (positive or negative) indicate whether error is going up or down\n",
    "- if error is going down, then it is in right direction\n",
    "- if going up, then its direction should be reversed\n",
    "- partial derivative respect to (m, b) is the line in graph below:\n",
    "    - line point to bottom right indicate error going down\n",
    "    - line point to top right, indicate error going up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://mathinsight.org/media/image/image/partial_derivative_as_slope.png\" width=\"500\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(width = 500, height = 200, url = 'http://mathinsight.org/media/image/image/partial_derivative_as_slope.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let (m, b) change a little at each step toward the lowest point\n",
    "> - a step = learning_rate * partial_derivate\n",
    "- do we add or minus a step to m and b? \n",
    "    - if partial_derivate_m > 0, then direction is wrong, direction needs reverse, m should going back or move left or get smaller, so m - learning_rate*partial_derivative_m\n",
    "    - if partial_derivate_m < 0, then direction is right, should keep going, m should move right or get larger, so m - learning_rate*partial_derivative_m\n",
    "    - same apply to b and its partial derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Move m and b for just one step == use whole training set to calc partial derivatives for current m and b\n",
    "> - move m and b for 1000 times, is to repeatedly calc partial derivative for current m and b 1000 times\n",
    "- m_new = m_current - learning_rate * partial_derivative_m\n",
    "- b_new = b_current - learning_rate * partial_derivative_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://spin.atomicobject.com/wp-content/uploads/linear_regression_gradient1.png\" width=\"500\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url = \"https://spin.atomicobject.com/wp-content/uploads/linear_regression_gradient1.png\",\n",
    "        width = 500, height = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to plot to get intuition of effect of each hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### demo.py source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gradient descent at b = 0, m = 0, error = 5565.10783448\n",
      "Running...\n",
      "After 1000 iterations b = 0.0889365199374, m = 1.47774408519, error = 112.614810116\n"
     ]
    }
   ],
   "source": [
    "%pycat demo.py\n",
    "\n",
    "from numpy import *\n",
    "\n",
    "\n",
    "# Secondary level function: compute_error_for_line_given_points() \n",
    "    # 1. purpose: to evaluate how well the line fit or describe the dataset \n",
    "    # 2. how to evaluate: distance of every point to the line \n",
    "    # 3. how to use the distance: distance -> square -> sum -> average\n",
    "    # 4. what kind of line: y = mx + b\n",
    "        # m is slope, b is y-intercept\n",
    "def compute_error_for_line_given_points(b, m, points):\n",
    "    \n",
    "    # initialize total error of all points\n",
    "    totalError = 0\n",
    "    \n",
    "    # get distance squared and sum them\n",
    "    for i in range(0, len(points)):\n",
    "        \n",
    "        # get each x value of a data point \n",
    "        x = points[i, 0]\n",
    "        # get each y value of a data point\n",
    "        y = points[i, 1]\n",
    "        # get distance, squared, and sum each up\n",
    "        totalError += (y - (m * x + b)) ** 2\n",
    "        \n",
    "    # return average\n",
    "    return totalError / float(len(points))\n",
    "\n",
    "\n",
    "# Secondary Level function: step_gradient()\n",
    "    # 1. search in gradient descent for just once\n",
    "def step_gradient(b_current, m_current, points, learningRate):\n",
    "    \n",
    "    # initialize m and b as 0\n",
    "    b_gradient = 0\n",
    "    m_gradient = 0\n",
    "    \n",
    "    # get num of data points\n",
    "    N = float(len(points))\n",
    "    \n",
    "    # loop every data point\n",
    "    for i in range(0, len(points)):\n",
    "        \n",
    "        # get x and y value for each point \n",
    "        x = points[i, 0]\n",
    "        y = points[i, 1]\n",
    "        \n",
    "        # calc partial derivative to b at each point, and add them up\n",
    "        b_gradient += -(2/N) * (y - ((m_current * x) + b_current))\n",
    "        \n",
    "        # calc partial derivative to m at each point, and add them up\n",
    "        m_gradient += -(2/N) * x * (y - ((m_current * x) + b_current))\n",
    "        \n",
    "    # move a step to get new m and new b\n",
    "    new_b = b_current - (learningRate * b_gradient)\n",
    "    new_m = m_current - (learningRate * m_gradient)\n",
    "    \n",
    "    # return new b and m in list not tuple nor dictionary\n",
    "    return [new_b, new_m]\n",
    "\n",
    "\n",
    "# Secondary Level function: gradient_descent_runner()\n",
    "    # 1. search in gradient descent for 1000 times e.g.\n",
    "def gradient_descent_runner(points, starting_b, starting_m, learning_rate, num_iterations):\n",
    "\n",
    "    # get inital m and b\n",
    "    b = starting_b\n",
    "    m = starting_m\n",
    "    \n",
    "    # iterate the process for num of times \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        # run the same function with new m and b over and over again\n",
    "        b, m = step_gradient(b, m, array(points), learning_rate)\n",
    "        \n",
    "    return [b, m]\n",
    "\n",
    "\n",
    "# High level function 1: run()\n",
    "def run():\n",
    "    \n",
    "    # step 1: import data\n",
    "    points = genfromtxt(\"data.csv\", delimiter=\",\")\n",
    "    \n",
    "    # ----------------------------\n",
    "    # step 2: set hyper-parameter\n",
    "    # 1. learning_rate: \n",
    "        # if too small, it could take very long to converge or find the best model\n",
    "        # if too large, it could never converge, or not find the best model\n",
    "        # is learning_rate == step_size?\n",
    "    learning_rate = 0.0001\n",
    "    \n",
    "    # ----------------------------\n",
    "    # 2. linear regression formula y = mx + b\n",
    "        # initial values are set to 0 \n",
    "    initial_b = 0 # initial y-intercept guess\n",
    "    initial_m = 0 # initial slope guess\n",
    "    \n",
    "    # 3. iterate 1000 times to gradually change the values of m and b, and finally find the best model\n",
    "    num_iterations = 1000\n",
    "\n",
    "    \n",
    "    # ----------------------------\n",
    "    # step 3: train model  \n",
    "    # 1. display initial m, b and error of model to truth\n",
    "    print \"Starting gradient descent at b = {0}, m = {1}, error = {2}\".format(initial_b, \\\n",
    "                      initial_m, compute_error_for_line_given_points(initial_b, initial_m, points))\n",
    "    print \"Running...\"\n",
    "    \n",
    "    # 2. calc final m, b from gradient_descent_runner()\n",
    "    [b, m] = gradient_descent_runner(points, initial_b, initial_m, learning_rate, num_iterations)\n",
    "    \n",
    "    # 3. print final m, b, error\n",
    "    print \"After {0} iterations b = {1}, m = {2}, error = {3}\".format(num_iterations, b, m, \\\n",
    "                      compute_error_for_line_given_points(b, m, points))\n",
    "\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gradient descent at b = 0, m = 0, error = 5565.10783448\n",
      "Running...\n",
      "After 1000 iterations b = 0.0889365199374, m = 1.47774408519, error = 112.614810116\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
